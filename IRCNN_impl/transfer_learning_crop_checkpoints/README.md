# Transfer Learning Crop Checkpoints
Hopefully the name of this folder and its contents is clear. The training started from `checkpoint-16.h5`, which was trained using crops of images on `instance-1` on Google Cloud. This was then trained for 10 epochs on `instance-2` to get `checkpoint-26.h5`. This training continued for a while, but because of a naming conflict, an exception was thrown and the training ran only for 15 *further* epochs, resulting in `checkpoint-41.h5`. At checkpoints 26 and 41, the MAE was very high, but the loss was low. As training progressed till `checkpoint-250.h5`, it seems that the loss soared to ~33k, while the MAE went down to ~96. The next step now is to then test this on the images and see its performance.
